{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import LSTMTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\Side-Projects\\10 Acadamy\\W4 Challenge\\Rossmann-Sales-Forecast\\src\\train.py:33: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.data = pd.read_csv(preprocessed_data_path, parse_dates=[\"Date\"])\n",
      "2025-01-14 20:57:26,549 - INFO - Data loaded successfully from ../data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize LSTMTrainer Class\n",
    "trainer = LSTMTrainer(\"../data/processed/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Stationarity of Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 20:58:50,499 - INFO - ADF Statistic for Store 1: -4.374784\n",
      "2025-01-14 20:58:50,499 - INFO - p-value: 0.000329\n",
      "2025-01-14 20:58:50,499 - INFO - The Sales data for Store 1 is stationary.\n"
     ]
    }
   ],
   "source": [
    "# Check stationarity\n",
    "trainer.check_stationarity(store_id=1, column=\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ACF and PACF\n",
    "# Generate ACF and PACF plots for the specified store ID\n",
    "trainer.plot_acf_pacf(store_id=1, column=\"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 21:02:40,302 - INFO - Train and validation data loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.X_train.shape=(762906, 97)\n",
      "self.X_val.shape=(254303, 97)\n",
      "self.y_train.shape=(762906, 1)\n",
      "self.y_val.shape=(254303, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_path = '../data/processed/X_train.pkl'\n",
    "X_val_path = '../data/processed/X_val.pkl'\n",
    "y_train_path = '../data/processed/y_train.pkl'\n",
    "y_val_path = '../data/processed/y_val.pkl'\n",
    "\n",
    "trainer.load_train_val_data(X_train_path, X_val_path, y_train_path, y_val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 21:03:20,536 - WARNING - Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "2025-01-14 21:03:20,929 - INFO - LSTM model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model\n",
    "trainer.build_model()\n",
    "trainer.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0124\n",
      "Epoch 1: val_loss improved from inf to 0.96284, saving model to ./checkpoints\\best_model\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 21:04:41,892 - INFO - Assets written to: ./checkpoints\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 11s 274ms/step - loss: 1.0124 - val_loss: 0.9628 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0124\n",
      "Epoch 2: val_loss did not improve from 0.96284\n",
      "39/39 [==============================] - 9s 215ms/step - loss: 1.0124 - val_loss: 0.9629 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0124\n",
      "Epoch 3: val_loss did not improve from 0.96284\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "39/39 [==============================] - 8s 202ms/step - loss: 1.0124 - val_loss: 0.9629 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0124\n",
      "Epoch 4: val_loss did not improve from 0.96284\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 1.0124 - val_loss: 0.9629 - lr: 5.0000e-06\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 5: val_loss did not improve from 0.96284\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 1.0123 - val_loss: 0.9629 - lr: 5.0000e-06\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 6: val_loss did not improve from 0.96284\n",
      "39/39 [==============================] - 8s 206ms/step - loss: 1.0123 - val_loss: 0.9629 - lr: 2.5000e-06\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 7: val_loss did not improve from 0.96284\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "39/39 [==============================] - 8s 209ms/step - loss: 1.0123 - val_loss: 0.9629 - lr: 2.5000e-06\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 8: val_loss did not improve from 0.96284\n",
      "39/39 [==============================] - 8s 210ms/step - loss: 1.0123 - val_loss: 0.9629 - lr: 1.2500e-06\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 9: val_loss did not improve from 0.96284\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "39/39 [==============================] - 8s 207ms/step - loss: 1.0123 - val_loss: 0.9630 - lr: 1.2500e-06\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 10: val_loss did not improve from 0.96284\n",
      "39/39 [==============================] - 8s 199ms/step - loss: 1.0123 - val_loss: 0.9630 - lr: 6.2500e-07\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.0123\n",
      "Epoch 11: val_loss did not improve from 0.96284\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "39/39 [==============================] - 8s 216ms/step - loss: 1.0123 - val_loss: 0.9630 - lr: 6.2500e-07\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 21:06:03,051 - INFO - Model training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM Model\n",
    "epochs = 20\n",
    "batch_size = 20000\n",
    "trainer.train_model(epochs=epochs, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
